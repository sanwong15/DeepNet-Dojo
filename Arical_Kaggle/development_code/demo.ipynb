{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "import gc\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "XGB_WEIGHT = 0.6500\n",
    "BASELINE_WEIGHT = 0.0056\n",
    "BASELINE_PRED = 0.0115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Data ---\n"
     ]
    }
   ],
   "source": [
    "# Load in Zillow dataset\n",
    "print( \"\\n--- Loading Data ---\")\n",
    "print(\"\\n - properties2016 [include properties (2016) features: NumOfBedRoom etc]\")\n",
    "print(\"\\n - train2016 contains the logError between Zillow Est and Real Sales (2016)\")\n",
    "print(\"\\n - properties2017 [include properties (2017) features: NumOfBedRoom etc]\")\n",
    "print(\"\\n - train2017 contains the logError between Zillow Est and Real Sales (2017)\")\n",
    "\n",
    "properties2016 = pd.read_csv('../input/properties_2016.csv',low_memory=False)\n",
    "train2016 = pd.read_csv(\"../input/train_2016_v2.csv\",parse_dates=['transactiondate'],low_memory=False)\n",
    "properties2017 = pd.read_csv('../input/properties_2017.csv',low_memory=False)\n",
    "train2017 = pd.read_csv(\"../input/train_2017.csv\",parse_dates=['transactiondate'],low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = (df[\"transactiondate\"].dt.year - 2016)*12 + df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"transaction_quarter\"] = (df[\"transactiondate\"].dt.year - 2016)*4 +df[\"transactiondate\"].dt.quarter\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Add the Time and Date Feature into dataset (Year-Month-Day-Quarter)\")\n",
    "train2016 = add_date_features(train2016)\n",
    "train2017 = add_date_features(train2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Train with Properties ...\n"
     ]
    }
   ],
   "source": [
    "print('Merge Train with Properties ...')\n",
    "train2016 = pd.merge(train2016, properties2016, how = 'left', on = 'parcelid')\n",
    "train2017 = pd.merge(train2017, properties2017, how = 'left', on = 'parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tax Features 2017  ...\n"
     ]
    }
   ],
   "source": [
    "print('Tax Features 2017  ...')\n",
    "train2017.iloc[:, train2017.columns.str.startswith('tax')] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sample ...\n"
     ]
    }
   ],
   "source": [
    "print('Loading Submission Sample ...')\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat Train 2016 & 2017 ...\n"
     ]
    }
   ],
   "source": [
    "print('Concat Train 2016 & 2017 ...')\n",
    "train_df = pd.concat([train2016, train2017], axis = 0)\n",
    "test_df = pd.merge(sample_submission[['ParcelId']], properties2016.rename(columns = {'parcelid': 'ParcelId'}), how = 'left', on = 'ParcelId')\n",
    "\n",
    "del properties2016, properties2017, train2016, train2017\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Showing the head of tran_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>transaction_day</th>\n",
       "      <th>transaction_quarter</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11016594</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>122754.0</td>\n",
       "      <td>360170.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>237416.0</td>\n",
       "      <td>6735.88</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>6.037107e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14366692</td>\n",
       "      <td>-0.1684</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>346458.0</td>\n",
       "      <td>585529.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>239071.0</td>\n",
       "      <td>10153.02</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12098116</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>61994.0</td>\n",
       "      <td>119906.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>57912.0</td>\n",
       "      <td>11484.48</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>6.037464e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12643413</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>171518.0</td>\n",
       "      <td>244880.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>73362.0</td>\n",
       "      <td>3048.74</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>6.037296e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14432541</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>169574.0</td>\n",
       "      <td>434551.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>264977.0</td>\n",
       "      <td>5488.96</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>6.059042e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror  transaction_year  transaction_month  transaction_day  \\\n",
       "0  11016594    0.0276              2016                  1                1   \n",
       "1  14366692   -0.1684              2016                  1                1   \n",
       "2  12098116   -0.0040              2016                  1                1   \n",
       "3  12643413    0.0218              2016                  1                2   \n",
       "4  14432541   -0.0050              2016                  1                2   \n",
       "\n",
       "   transaction_quarter  airconditioningtypeid  architecturalstyletypeid  \\\n",
       "0                    1                    1.0                    -999.0   \n",
       "1                    1                 -999.0                    -999.0   \n",
       "2                    1                    1.0                    -999.0   \n",
       "3                    1                    1.0                    -999.0   \n",
       "4                    1                 -999.0                    -999.0   \n",
       "\n",
       "   basementsqft  bathroomcnt         ...           numberofstories  \\\n",
       "0        -999.0          2.0         ...                    -999.0   \n",
       "1        -999.0          3.5         ...                    -999.0   \n",
       "2        -999.0          3.0         ...                    -999.0   \n",
       "3        -999.0          2.0         ...                    -999.0   \n",
       "4        -999.0          2.5         ...                       2.0   \n",
       "\n",
       "   fireplaceflag  structuretaxvaluedollarcnt  taxvaluedollarcnt  \\\n",
       "0           -999                    122754.0           360170.0   \n",
       "1           -999                    346458.0           585529.0   \n",
       "2           -999                     61994.0           119906.0   \n",
       "3           -999                    171518.0           244880.0   \n",
       "4           -999                    169574.0           434551.0   \n",
       "\n",
       "   assessmentyear  landtaxvaluedollarcnt  taxamount  taxdelinquencyflag  \\\n",
       "0          2015.0               237416.0    6735.88                -999   \n",
       "1          2015.0               239071.0   10153.02                -999   \n",
       "2          2015.0                57912.0   11484.48                -999   \n",
       "3          2015.0                73362.0    3048.74                -999   \n",
       "4          2015.0               264977.0    5488.96                -999   \n",
       "\n",
       "   taxdelinquencyyear  censustractandblock  \n",
       "0              -999.0         6.037107e+13  \n",
       "1              -999.0        -9.990000e+02  \n",
       "2              -999.0         6.037464e+13  \n",
       "3              -999.0         6.037296e+13  \n",
       "4              -999.0         6.059042e+13  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n Showing the head of tran_df\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Save train_df to csv for more indepth look\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Save train_df to csv for more indepth look\")\n",
    "train_df.to_csv('train_df.csv', float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove missing data fields ...\n",
      "We exclude: 15\n"
     ]
    }
   ],
   "source": [
    "print('Remove missing data fields ...')\n",
    "\n",
    "missing_perc_thresh = 0.98\n",
    "exclude_missing = []\n",
    "num_rows = train_df.shape[0]\n",
    "for c in train_df.columns:\n",
    "    num_missing = train_df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_missing))\n",
    "\n",
    "del num_rows, missing_perc_thresh\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove features with one unique value !!\n",
      "We exclude: 9\n"
     ]
    }
   ],
   "source": [
    "# Not sure why we need to remove features with one unique value\n",
    "print (\"Remove features with one unique value !!\")\n",
    "exclude_unique = []\n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0:\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define training features !!\n",
      "We use these for training: 42\n"
     ]
    }
   ],
   "source": [
    "print (\"Define training features !!\")\n",
    "exclude_other = ['parcelid', 'logerror','propertyzoningdesc']\n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)\n",
    "print(\"We use these for training: %s\" % len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define categorial features !!\n",
      "Cat features are: ['transaction_year', 'transaction_month', 'transaction_day', 'transaction_quarter', 'airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'yearbuilt', 'assessmentyear']\n",
      "Replacing NaN values by -999 !!\n"
     ]
    }
   ],
   "source": [
    "print (\"Define categorial features !!\")\n",
    "cat_feature_inds = []\n",
    "cat_unique_thresh = 1000\n",
    "for i, c in enumerate(train_features):\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if num_uniques < cat_unique_thresh \\\n",
    "       and not 'sqft' in c \\\n",
    "       and not 'cnt' in c \\\n",
    "       and not 'nbr' in c \\\n",
    "       and not 'number' in c:\n",
    "        cat_feature_inds.append(i)\n",
    "        \n",
    "print(\"Cat features are: %s\" % [train_features[ind] for ind in cat_feature_inds])\n",
    "\n",
    "print (\"Replacing NaN values by -999 !!\")\n",
    "train_df.fillna(-999, inplace=True)\n",
    "test_df.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time !!\n",
      "(167888, 42) (167888,) (167888,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training time !!\")\n",
    "X_train = train_df[train_features]\n",
    "y_train = train_df.logerror\n",
    "y_train_GBM = train_df['logerror'].values\n",
    "print(X_train.shape, y_train.shape, y_train_GBM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data for LightGBM ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Try to debug the LightGBM\n",
    "print( \"\\nProcessing data for LightGBM ...\" )\n",
    "for c, dtype in zip(X_train.columns, X_train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        X_train[c] = X_train[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 42)\n"
     ]
    }
   ],
   "source": [
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n",
    "test_df = add_date_features(test_df)\n",
    "X_test = test_df[train_features]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0689284\ttotal: 1.21s\tremaining: 12m 42s\n",
      "1:\tlearn: 0.0687339\ttotal: 2.12s\tremaining: 11m 5s\n",
      "2:\tlearn: 0.0686147\ttotal: 3.03s\tremaining: 10m 32s\n",
      "3:\tlearn: 0.0685249\ttotal: 4.62s\tremaining: 12m 2s\n",
      "4:\tlearn: 0.0684645\ttotal: 5.47s\tremaining: 11m 24s\n",
      "5:\tlearn: 0.0684146\ttotal: 6.38s\tremaining: 11m 3s\n",
      "6:\tlearn: 0.0683836\ttotal: 7.3s\tremaining: 10m 49s\n",
      "7:\tlearn: 0.0683441\ttotal: 8.19s\tremaining: 10m 36s\n",
      "8:\tlearn: 0.0683068\ttotal: 8.86s\tremaining: 10m 11s\n",
      "9:\tlearn: 0.0682771\ttotal: 9.62s\tremaining: 9m 56s\n",
      "10:\tlearn: 0.0682595\ttotal: 10.5s\tremaining: 9m 48s\n",
      "11:\tlearn: 0.0682460\ttotal: 11.2s\tremaining: 9m 34s\n",
      "12:\tlearn: 0.0682315\ttotal: 12s\tremaining: 9m 27s\n",
      "13:\tlearn: 0.0682165\ttotal: 12.7s\tremaining: 9m 19s\n",
      "14:\tlearn: 0.0681989\ttotal: 13.7s\tremaining: 9m 22s\n",
      "15:\tlearn: 0.0681881\ttotal: 14.4s\tremaining: 9m 11s\n",
      "16:\tlearn: 0.0681701\ttotal: 15.3s\tremaining: 9m 11s\n",
      "17:\tlearn: 0.0681500\ttotal: 16.1s\tremaining: 9m 7s\n",
      "18:\tlearn: 0.0681442\ttotal: 16.8s\tremaining: 8m 58s\n",
      "19:\tlearn: 0.0681221\ttotal: 17.7s\tremaining: 9m\n",
      "20:\tlearn: 0.0681103\ttotal: 19s\tremaining: 9m 11s\n",
      "21:\tlearn: 0.0680991\ttotal: 19.8s\tremaining: 9m 6s\n",
      "22:\tlearn: 0.0680855\ttotal: 20.5s\tremaining: 9m 1s\n",
      "23:\tlearn: 0.0680709\ttotal: 21.3s\tremaining: 8m 58s\n",
      "24:\tlearn: 0.0680542\ttotal: 22.1s\tremaining: 8m 54s\n",
      "25:\tlearn: 0.0680446\ttotal: 22.8s\tremaining: 8m 49s\n",
      "26:\tlearn: 0.0680311\ttotal: 23.5s\tremaining: 8m 44s\n",
      "27:\tlearn: 0.0680207\ttotal: 24.3s\tremaining: 8m 42s\n",
      "28:\tlearn: 0.0680116\ttotal: 25.5s\tremaining: 8m 48s\n",
      "29:\tlearn: 0.0680014\ttotal: 26.4s\tremaining: 8m 48s\n",
      "30:\tlearn: 0.0679929\ttotal: 27.4s\tremaining: 8m 49s\n",
      "31:\tlearn: 0.0679821\ttotal: 28.2s\tremaining: 8m 47s\n",
      "32:\tlearn: 0.0679760\ttotal: 29s\tremaining: 8m 44s\n",
      "33:\tlearn: 0.0679666\ttotal: 30s\tremaining: 8m 46s\n",
      "34:\tlearn: 0.0679587\ttotal: 30.7s\tremaining: 8m 42s\n",
      "35:\tlearn: 0.0679530\ttotal: 31.4s\tremaining: 8m 38s\n",
      "36:\tlearn: 0.0679471\ttotal: 32.4s\tremaining: 8m 39s\n",
      "37:\tlearn: 0.0679374\ttotal: 33.2s\tremaining: 8m 37s\n",
      "38:\tlearn: 0.0679318\ttotal: 34.2s\tremaining: 8m 38s\n",
      "39:\tlearn: 0.0679246\ttotal: 35.6s\tremaining: 8m 45s\n",
      "40:\tlearn: 0.0679162\ttotal: 36.4s\tremaining: 8m 43s\n",
      "41:\tlearn: 0.0679082\ttotal: 37.1s\tremaining: 8m 40s\n",
      "42:\tlearn: 0.0679012\ttotal: 37.8s\tremaining: 8m 35s\n",
      "43:\tlearn: 0.0678942\ttotal: 38.5s\tremaining: 8m 33s\n",
      "44:\tlearn: 0.0678878\ttotal: 39.2s\tremaining: 8m 29s\n",
      "45:\tlearn: 0.0678808\ttotal: 39.9s\tremaining: 8m 26s\n",
      "46:\tlearn: 0.0678745\ttotal: 40.6s\tremaining: 8m 23s\n",
      "47:\tlearn: 0.0678696\ttotal: 41.3s\tremaining: 8m 21s\n",
      "48:\tlearn: 0.0678610\ttotal: 42s\tremaining: 8m 18s\n",
      "49:\tlearn: 0.0678565\ttotal: 43.2s\tremaining: 8m 20s\n",
      "50:\tlearn: 0.0678524\ttotal: 45s\tremaining: 8m 31s\n",
      "51:\tlearn: 0.0678453\ttotal: 46.3s\tremaining: 8m 34s\n",
      "52:\tlearn: 0.0678429\ttotal: 47.4s\tremaining: 8m 36s\n",
      "53:\tlearn: 0.0678328\ttotal: 48.6s\tremaining: 8m 38s\n",
      "54:\tlearn: 0.0678252\ttotal: 49.4s\tremaining: 8m 36s\n",
      "55:\tlearn: 0.0678174\ttotal: 50.3s\tremaining: 8m 35s\n",
      "56:\tlearn: 0.0678144\ttotal: 51.7s\tremaining: 8m 39s\n",
      "57:\tlearn: 0.0678064\ttotal: 52.9s\tremaining: 8m 41s\n",
      "58:\tlearn: 0.0677999\ttotal: 55.1s\tremaining: 8m 53s\n",
      "59:\tlearn: 0.0677910\ttotal: 56.3s\tremaining: 8m 55s\n",
      "60:\tlearn: 0.0677829\ttotal: 57.2s\tremaining: 8m 53s\n",
      "61:\tlearn: 0.0677807\ttotal: 58.5s\tremaining: 8m 56s\n",
      "62:\tlearn: 0.0677761\ttotal: 59.7s\tremaining: 8m 56s\n",
      "63:\tlearn: 0.0677688\ttotal: 1m\tremaining: 8m 56s\n",
      "64:\tlearn: 0.0677633\ttotal: 1m 1s\tremaining: 8m 56s\n",
      "65:\tlearn: 0.0677596\ttotal: 1m 2s\tremaining: 8m 58s\n",
      "66:\tlearn: 0.0677547\ttotal: 1m 3s\tremaining: 8m 55s\n",
      "67:\tlearn: 0.0677497\ttotal: 1m 4s\tremaining: 8m 54s\n",
      "68:\tlearn: 0.0677457\ttotal: 1m 6s\tremaining: 8m 58s\n",
      "69:\tlearn: 0.0677366\ttotal: 1m 7s\tremaining: 9m 2s\n",
      "70:\tlearn: 0.0677346\ttotal: 1m 9s\tremaining: 9m 9s\n",
      "71:\tlearn: 0.0677328\ttotal: 1m 10s\tremaining: 9m 9s\n",
      "72:\tlearn: 0.0677225\ttotal: 1m 11s\tremaining: 9m 5s\n",
      "73:\tlearn: 0.0677166\ttotal: 1m 12s\tremaining: 9m 2s\n",
      "74:\tlearn: 0.0677089\ttotal: 1m 12s\tremaining: 8m 59s\n",
      "75:\tlearn: 0.0677018\ttotal: 1m 13s\tremaining: 8m 57s\n",
      "76:\tlearn: 0.0676945\ttotal: 1m 14s\tremaining: 8m 54s\n",
      "77:\tlearn: 0.0676905\ttotal: 1m 15s\tremaining: 8m 53s\n",
      "78:\tlearn: 0.0676811\ttotal: 1m 16s\tremaining: 8m 50s\n",
      "79:\tlearn: 0.0676749\ttotal: 1m 17s\tremaining: 8m 49s\n",
      "80:\tlearn: 0.0676705\ttotal: 1m 18s\tremaining: 8m 50s\n",
      "81:\tlearn: 0.0676665\ttotal: 1m 19s\tremaining: 8m 50s\n",
      "82:\tlearn: 0.0676582\ttotal: 1m 20s\tremaining: 8m 49s\n",
      "83:\tlearn: 0.0676507\ttotal: 1m 21s\tremaining: 8m 46s\n",
      "84:\tlearn: 0.0676426\ttotal: 1m 21s\tremaining: 8m 44s\n",
      "85:\tlearn: 0.0676384\ttotal: 1m 22s\tremaining: 8m 43s\n",
      "86:\tlearn: 0.0676358\ttotal: 1m 23s\tremaining: 8m 41s\n",
      "87:\tlearn: 0.0676308\ttotal: 1m 24s\tremaining: 8m 38s\n",
      "88:\tlearn: 0.0676248\ttotal: 1m 24s\tremaining: 8m 36s\n",
      "89:\tlearn: 0.0676206\ttotal: 1m 25s\tremaining: 8m 33s\n",
      "90:\tlearn: 0.0676181\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "91:\tlearn: 0.0676165\ttotal: 1m 27s\tremaining: 8m 30s\n",
      "92:\tlearn: 0.0676133\ttotal: 1m 27s\tremaining: 8m 27s\n",
      "93:\tlearn: 0.0676070\ttotal: 1m 28s\tremaining: 8m 24s\n",
      "94:\tlearn: 0.0676023\ttotal: 1m 29s\tremaining: 8m 22s\n",
      "95:\tlearn: 0.0675998\ttotal: 1m 30s\tremaining: 8m 20s\n",
      "96:\tlearn: 0.0675965\ttotal: 1m 30s\tremaining: 8m 18s\n",
      "97:\tlearn: 0.0675931\ttotal: 1m 31s\tremaining: 8m 18s\n",
      "98:\tlearn: 0.0675858\ttotal: 1m 32s\tremaining: 8m 17s\n",
      "99:\tlearn: 0.0675813\ttotal: 1m 33s\tremaining: 8m 15s\n",
      "100:\tlearn: 0.0675759\ttotal: 1m 34s\tremaining: 8m 13s\n",
      "101:\tlearn: 0.0675735\ttotal: 1m 34s\tremaining: 8m 10s\n",
      "102:\tlearn: 0.0675697\ttotal: 1m 35s\tremaining: 8m 9s\n",
      "103:\tlearn: 0.0675665\ttotal: 1m 36s\tremaining: 8m 9s\n",
      "104:\tlearn: 0.0675641\ttotal: 1m 37s\tremaining: 8m 9s\n",
      "105:\tlearn: 0.0675595\ttotal: 1m 38s\tremaining: 8m 7s\n",
      "106:\tlearn: 0.0675575\ttotal: 1m 40s\tremaining: 8m 10s\n",
      "107:\tlearn: 0.0675541\ttotal: 1m 42s\tremaining: 8m 14s\n",
      "108:\tlearn: 0.0675484\ttotal: 1m 42s\tremaining: 8m 11s\n",
      "109:\tlearn: 0.0675445\ttotal: 1m 43s\tremaining: 8m 10s\n",
      "110:\tlearn: 0.0675401\ttotal: 1m 44s\tremaining: 8m 9s\n",
      "111:\tlearn: 0.0675385\ttotal: 1m 45s\tremaining: 8m 6s\n",
      "112:\tlearn: 0.0675356\ttotal: 1m 45s\tremaining: 8m 4s\n",
      "113:\tlearn: 0.0675256\ttotal: 1m 46s\tremaining: 8m 3s\n",
      "114:\tlearn: 0.0675239\ttotal: 1m 47s\tremaining: 8m 2s\n",
      "115:\tlearn: 0.0675204\ttotal: 1m 48s\tremaining: 8m\n",
      "116:\tlearn: 0.0675160\ttotal: 1m 49s\tremaining: 7m 58s\n",
      "117:\tlearn: 0.0675120\ttotal: 1m 49s\tremaining: 7m 56s\n",
      "118:\tlearn: 0.0675079\ttotal: 1m 50s\tremaining: 7m 54s\n",
      "119:\tlearn: 0.0675055\ttotal: 1m 51s\tremaining: 7m 52s\n",
      "120:\tlearn: 0.0675022\ttotal: 1m 52s\tremaining: 7m 51s\n",
      "121:\tlearn: 0.0674965\ttotal: 1m 52s\tremaining: 7m 49s\n",
      "122:\tlearn: 0.0674911\ttotal: 1m 53s\tremaining: 7m 47s\n",
      "123:\tlearn: 0.0674861\ttotal: 1m 54s\tremaining: 7m 46s\n",
      "124:\tlearn: 0.0674807\ttotal: 1m 55s\tremaining: 7m 45s\n",
      "125:\tlearn: 0.0674752\ttotal: 1m 56s\tremaining: 7m 44s\n",
      "126:\tlearn: 0.0674739\ttotal: 1m 57s\tremaining: 7m 44s\n",
      "127:\tlearn: 0.0674712\ttotal: 1m 58s\tremaining: 7m 43s\n",
      "128:\tlearn: 0.0674686\ttotal: 1m 58s\tremaining: 7m 41s\n",
      "129:\tlearn: 0.0674650\ttotal: 1m 59s\tremaining: 7m 39s\n",
      "130:\tlearn: 0.0674614\ttotal: 2m\tremaining: 7m 38s\n",
      "131:\tlearn: 0.0674585\ttotal: 2m\tremaining: 7m 36s\n",
      "132:\tlearn: 0.0674538\ttotal: 2m 1s\tremaining: 7m 35s\n",
      "133:\tlearn: 0.0674496\ttotal: 2m 2s\tremaining: 7m 34s\n",
      "134:\tlearn: 0.0674476\ttotal: 2m 3s\tremaining: 7m 33s\n",
      "135:\tlearn: 0.0674455\ttotal: 2m 4s\tremaining: 7m 33s\n",
      "136:\tlearn: 0.0674426\ttotal: 2m 6s\tremaining: 7m 34s\n",
      "137:\tlearn: 0.0674389\ttotal: 2m 9s\tremaining: 7m 40s\n",
      "138:\tlearn: 0.0674349\ttotal: 2m 12s\tremaining: 7m 48s\n",
      "139:\tlearn: 0.0674313\ttotal: 2m 14s\tremaining: 7m 50s\n",
      "140:\tlearn: 0.0674285\ttotal: 2m 16s\tremaining: 7m 52s\n",
      "141:\tlearn: 0.0674237\ttotal: 2m 17s\tremaining: 7m 51s\n",
      "142:\tlearn: 0.0674212\ttotal: 2m 18s\tremaining: 7m 50s\n",
      "143:\tlearn: 0.0674191\ttotal: 2m 19s\tremaining: 7m 49s\n",
      "144:\tlearn: 0.0674163\ttotal: 2m 20s\tremaining: 7m 49s\n",
      "145:\tlearn: 0.0674150\ttotal: 2m 21s\tremaining: 7m 48s\n",
      "146:\tlearn: 0.0674123\ttotal: 2m 22s\tremaining: 7m 48s\n",
      "147:\tlearn: 0.0674092\ttotal: 2m 23s\tremaining: 7m 48s\n",
      "148:\tlearn: 0.0674052\ttotal: 2m 26s\tremaining: 7m 51s\n",
      "149:\tlearn: 0.0674015\ttotal: 2m 27s\tremaining: 7m 50s\n",
      "150:\tlearn: 0.0673937\ttotal: 2m 28s\tremaining: 7m 49s\n",
      "151:\tlearn: 0.0673908\ttotal: 2m 29s\tremaining: 7m 49s\n",
      "152:\tlearn: 0.0673875\ttotal: 2m 31s\tremaining: 7m 51s\n",
      "153:\tlearn: 0.0673867\ttotal: 2m 32s\tremaining: 7m 51s\n",
      "154:\tlearn: 0.0673836\ttotal: 2m 33s\tremaining: 7m 51s\n",
      "155:\tlearn: 0.0673800\ttotal: 2m 35s\tremaining: 7m 52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156:\tlearn: 0.0673782\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "157:\tlearn: 0.0673748\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "158:\tlearn: 0.0673733\ttotal: 2m 41s\tremaining: 7m 56s\n",
      "159:\tlearn: 0.0673696\ttotal: 2m 48s\tremaining: 8m 13s\n",
      "160:\tlearn: 0.0673661\ttotal: 2m 52s\tremaining: 8m 22s\n",
      "161:\tlearn: 0.0673634\ttotal: 2m 55s\tremaining: 8m 28s\n",
      "162:\tlearn: 0.0673622\ttotal: 2m 58s\tremaining: 8m 30s\n",
      "163:\tlearn: 0.0673579\ttotal: 3m\tremaining: 8m 32s\n",
      "164:\tlearn: 0.0673542\ttotal: 3m 2s\tremaining: 8m 34s\n",
      "165:\tlearn: 0.0673505\ttotal: 3m 3s\tremaining: 8m 33s\n",
      "166:\tlearn: 0.0673442\ttotal: 3m 4s\tremaining: 8m 31s\n",
      "167:\tlearn: 0.0673411\ttotal: 3m 6s\tremaining: 8m 32s\n",
      "168:\tlearn: 0.0673360\ttotal: 3m 7s\tremaining: 8m 32s\n",
      "169:\tlearn: 0.0673324\ttotal: 3m 9s\tremaining: 8m 34s\n",
      "170:\tlearn: 0.0673293\ttotal: 3m 11s\tremaining: 8m 34s\n",
      "171:\tlearn: 0.0673242\ttotal: 3m 12s\tremaining: 8m 32s\n",
      "172:\tlearn: 0.0673202\ttotal: 3m 13s\tremaining: 8m 31s\n",
      "173:\tlearn: 0.0673162\ttotal: 3m 14s\tremaining: 8m 29s\n",
      "174:\tlearn: 0.0673114\ttotal: 3m 15s\tremaining: 8m 27s\n",
      "175:\tlearn: 0.0673087\ttotal: 3m 15s\tremaining: 8m 25s\n",
      "176:\tlearn: 0.0673049\ttotal: 3m 16s\tremaining: 8m 23s\n",
      "177:\tlearn: 0.0672993\ttotal: 3m 17s\tremaining: 8m 21s\n",
      "178:\tlearn: 0.0672977\ttotal: 3m 18s\tremaining: 8m 20s\n",
      "179:\tlearn: 0.0672918\ttotal: 3m 20s\tremaining: 8m 20s\n",
      "180:\tlearn: 0.0672879\ttotal: 3m 21s\tremaining: 8m 19s\n",
      "181:\tlearn: 0.0672851\ttotal: 3m 23s\tremaining: 8m 19s\n",
      "182:\tlearn: 0.0672834\ttotal: 3m 25s\tremaining: 8m 21s\n",
      "183:\tlearn: 0.0672815\ttotal: 3m 30s\tremaining: 8m 29s\n",
      "184:\tlearn: 0.0672784\ttotal: 3m 41s\tremaining: 8m 51s\n",
      "185:\tlearn: 0.0672765\ttotal: 3m 49s\tremaining: 9m 7s\n",
      "186:\tlearn: 0.0672731\ttotal: 3m 54s\tremaining: 9m 16s\n",
      "187:\tlearn: 0.0672702\ttotal: 3m 57s\tremaining: 9m 19s\n",
      "188:\tlearn: 0.0672661\ttotal: 4m\tremaining: 9m 20s\n",
      "189:\tlearn: 0.0672617\ttotal: 4m 2s\tremaining: 9m 21s\n",
      "190:\tlearn: 0.0672588\ttotal: 4m 4s\tremaining: 9m 21s\n",
      "191:\tlearn: 0.0672560\ttotal: 4m 6s\tremaining: 9m 23s\n",
      "192:\tlearn: 0.0672506\ttotal: 4m 10s\tremaining: 9m 28s\n",
      "193:\tlearn: 0.0672486\ttotal: 4m 14s\tremaining: 9m 32s\n",
      "194:\tlearn: 0.0672455\ttotal: 4m 17s\tremaining: 9m 34s\n",
      "195:\tlearn: 0.0672417\ttotal: 4m 19s\tremaining: 9m 34s\n",
      "196:\tlearn: 0.0672378\ttotal: 4m 20s\tremaining: 9m 33s\n",
      "197:\tlearn: 0.0672345\ttotal: 4m 22s\tremaining: 9m 32s\n",
      "198:\tlearn: 0.0672336\ttotal: 4m 23s\tremaining: 9m 30s\n",
      "199:\tlearn: 0.0672314\ttotal: 4m 25s\tremaining: 9m 30s\n",
      "200:\tlearn: 0.0672291\ttotal: 4m 27s\tremaining: 9m 31s\n",
      "201:\tlearn: 0.0672254\ttotal: 4m 29s\tremaining: 9m 30s\n",
      "202:\tlearn: 0.0672215\ttotal: 4m 30s\tremaining: 9m 28s\n",
      "203:\tlearn: 0.0672149\ttotal: 4m 31s\tremaining: 9m 26s\n",
      "204:\tlearn: 0.0672116\ttotal: 4m 32s\tremaining: 9m 24s\n",
      "205:\tlearn: 0.0672096\ttotal: 4m 34s\tremaining: 9m 24s\n",
      "206:\tlearn: 0.0672065\ttotal: 4m 35s\tremaining: 9m 23s\n",
      "207:\tlearn: 0.0672039\ttotal: 4m 37s\tremaining: 9m 22s\n",
      "208:\tlearn: 0.0671974\ttotal: 4m 38s\tremaining: 9m 21s\n",
      "209:\tlearn: 0.0671930\ttotal: 4m 40s\tremaining: 9m 20s\n",
      "210:\tlearn: 0.0671881\ttotal: 4m 41s\tremaining: 9m 19s\n",
      "211:\tlearn: 0.0671846\ttotal: 4m 42s\tremaining: 9m 17s\n",
      "212:\tlearn: 0.0671818\ttotal: 4m 43s\tremaining: 9m 15s\n",
      "213:\tlearn: 0.0671794\ttotal: 4m 45s\tremaining: 9m 15s\n",
      "214:\tlearn: 0.0671747\ttotal: 4m 47s\tremaining: 9m 13s\n",
      "215:\tlearn: 0.0671719\ttotal: 4m 49s\tremaining: 9m 14s\n",
      "216:\tlearn: 0.0671695\ttotal: 4m 51s\tremaining: 9m 14s\n",
      "217:\tlearn: 0.0671667\ttotal: 4m 52s\tremaining: 9m 12s\n",
      "218:\tlearn: 0.0671640\ttotal: 4m 53s\tremaining: 9m 10s\n",
      "219:\tlearn: 0.0671578\ttotal: 4m 54s\tremaining: 9m 8s\n",
      "220:\tlearn: 0.0671557\ttotal: 4m 55s\tremaining: 9m 6s\n",
      "221:\tlearn: 0.0671503\ttotal: 4m 56s\tremaining: 9m 4s\n",
      "222:\tlearn: 0.0671473\ttotal: 4m 56s\tremaining: 9m 1s\n",
      "223:\tlearn: 0.0671448\ttotal: 4m 57s\tremaining: 8m 59s\n",
      "224:\tlearn: 0.0671424\ttotal: 4m 58s\tremaining: 8m 58s\n",
      "225:\tlearn: 0.0671384\ttotal: 4m 59s\tremaining: 8m 55s\n",
      "226:\tlearn: 0.0671358\ttotal: 5m\tremaining: 8m 53s\n",
      "227:\tlearn: 0.0671317\ttotal: 5m 1s\tremaining: 8m 51s\n",
      "228:\tlearn: 0.0671284\ttotal: 5m 2s\tremaining: 8m 49s\n",
      "229:\tlearn: 0.0671263\ttotal: 5m 3s\tremaining: 8m 47s\n",
      "230:\tlearn: 0.0671235\ttotal: 5m 4s\tremaining: 8m 45s\n",
      "231:\tlearn: 0.0671216\ttotal: 5m 6s\tremaining: 8m 45s\n",
      "232:\tlearn: 0.0671201\ttotal: 5m 7s\tremaining: 8m 43s\n",
      "233:\tlearn: 0.0671179\ttotal: 5m 8s\tremaining: 8m 41s\n",
      "234:\tlearn: 0.0671155\ttotal: 5m 8s\tremaining: 8m 39s\n",
      "235:\tlearn: 0.0671105\ttotal: 5m 9s\tremaining: 8m 36s\n",
      "236:\tlearn: 0.0671096\ttotal: 5m 10s\tremaining: 8m 34s\n",
      "237:\tlearn: 0.0671074\ttotal: 5m 11s\tremaining: 8m 32s\n",
      "238:\tlearn: 0.0671053\ttotal: 5m 12s\tremaining: 8m 30s\n",
      "239:\tlearn: 0.0671029\ttotal: 5m 12s\tremaining: 8m 28s\n",
      "240:\tlearn: 0.0670983\ttotal: 5m 13s\tremaining: 8m 25s\n",
      "241:\tlearn: 0.0670937\ttotal: 5m 14s\tremaining: 8m 24s\n",
      "242:\tlearn: 0.0670910\ttotal: 5m 15s\tremaining: 8m 22s\n",
      "243:\tlearn: 0.0670886\ttotal: 5m 16s\tremaining: 8m 20s\n",
      "244:\tlearn: 0.0670859\ttotal: 5m 16s\tremaining: 8m 17s\n",
      "245:\tlearn: 0.0670822\ttotal: 5m 17s\tremaining: 8m 15s\n",
      "246:\tlearn: 0.0670784\ttotal: 5m 18s\tremaining: 8m 13s\n",
      "247:\tlearn: 0.0670758\ttotal: 5m 18s\tremaining: 8m 11s\n",
      "248:\tlearn: 0.0670745\ttotal: 5m 19s\tremaining: 8m 8s\n",
      "249:\tlearn: 0.0670728\ttotal: 5m 20s\tremaining: 8m 6s\n",
      "250:\tlearn: 0.0670700\ttotal: 5m 20s\tremaining: 8m 4s\n",
      "251:\tlearn: 0.0670688\ttotal: 5m 21s\tremaining: 8m 2s\n",
      "252:\tlearn: 0.0670673\ttotal: 5m 22s\tremaining: 8m\n",
      "253:\tlearn: 0.0670639\ttotal: 5m 22s\tremaining: 7m 57s\n",
      "254:\tlearn: 0.0670608\ttotal: 5m 23s\tremaining: 7m 55s\n",
      "255:\tlearn: 0.0670568\ttotal: 5m 24s\tremaining: 7m 53s\n",
      "256:\tlearn: 0.0670538\ttotal: 5m 24s\tremaining: 7m 51s\n",
      "257:\tlearn: 0.0670512\ttotal: 5m 25s\tremaining: 7m 49s\n",
      "258:\tlearn: 0.0670489\ttotal: 5m 26s\tremaining: 7m 47s\n",
      "259:\tlearn: 0.0670455\ttotal: 5m 27s\tremaining: 7m 45s\n",
      "260:\tlearn: 0.0670439\ttotal: 5m 27s\tremaining: 7m 43s\n",
      "261:\tlearn: 0.0670395\ttotal: 5m 28s\tremaining: 7m 41s\n",
      "262:\tlearn: 0.0670358\ttotal: 5m 28s\tremaining: 7m 39s\n",
      "263:\tlearn: 0.0670341\ttotal: 5m 29s\tremaining: 7m 36s\n",
      "264:\tlearn: 0.0670327\ttotal: 5m 30s\tremaining: 7m 34s\n",
      "265:\tlearn: 0.0670300\ttotal: 5m 31s\tremaining: 7m 33s\n",
      "266:\tlearn: 0.0670279\ttotal: 5m 31s\tremaining: 7m 30s\n",
      "267:\tlearn: 0.0670253\ttotal: 5m 32s\tremaining: 7m 28s\n",
      "268:\tlearn: 0.0670199\ttotal: 5m 33s\tremaining: 7m 27s\n",
      "269:\tlearn: 0.0670155\ttotal: 5m 33s\tremaining: 7m 24s\n",
      "270:\tlearn: 0.0670138\ttotal: 5m 34s\tremaining: 7m 22s\n",
      "271:\tlearn: 0.0670109\ttotal: 5m 34s\tremaining: 7m 20s\n",
      "272:\tlearn: 0.0670079\ttotal: 5m 35s\tremaining: 7m 18s\n",
      "273:\tlearn: 0.0670061\ttotal: 5m 36s\tremaining: 7m 16s\n",
      "274:\tlearn: 0.0670014\ttotal: 5m 36s\tremaining: 7m 14s\n",
      "275:\tlearn: 0.0669993\ttotal: 5m 37s\tremaining: 7m 12s\n",
      "276:\tlearn: 0.0669938\ttotal: 5m 37s\tremaining: 7m 10s\n",
      "277:\tlearn: 0.0669898\ttotal: 5m 38s\tremaining: 7m 8s\n",
      "278:\tlearn: 0.0669863\ttotal: 5m 39s\tremaining: 7m 6s\n",
      "279:\tlearn: 0.0669841\ttotal: 5m 39s\tremaining: 7m 4s\n",
      "280:\tlearn: 0.0669816\ttotal: 5m 40s\tremaining: 7m 2s\n",
      "281:\tlearn: 0.0669792\ttotal: 5m 40s\tremaining: 7m\n",
      "282:\tlearn: 0.0669783\ttotal: 5m 41s\tremaining: 6m 58s\n",
      "283:\tlearn: 0.0669775\ttotal: 5m 42s\tremaining: 6m 56s\n",
      "284:\tlearn: 0.0669742\ttotal: 5m 42s\tremaining: 6m 54s\n",
      "285:\tlearn: 0.0669727\ttotal: 5m 43s\tremaining: 6m 52s\n",
      "286:\tlearn: 0.0669673\ttotal: 5m 43s\tremaining: 6m 50s\n",
      "287:\tlearn: 0.0669656\ttotal: 5m 44s\tremaining: 6m 49s\n",
      "288:\tlearn: 0.0669616\ttotal: 5m 45s\tremaining: 6m 47s\n",
      "289:\tlearn: 0.0669584\ttotal: 5m 45s\tremaining: 6m 45s\n",
      "290:\tlearn: 0.0669548\ttotal: 5m 46s\tremaining: 6m 43s\n",
      "291:\tlearn: 0.0669508\ttotal: 5m 46s\tremaining: 6m 41s\n",
      "292:\tlearn: 0.0669486\ttotal: 5m 47s\tremaining: 6m 39s\n",
      "293:\tlearn: 0.0669465\ttotal: 5m 48s\tremaining: 6m 37s\n",
      "294:\tlearn: 0.0669447\ttotal: 5m 49s\tremaining: 6m 36s\n",
      "295:\tlearn: 0.0669413\ttotal: 5m 49s\tremaining: 6m 34s\n",
      "296:\tlearn: 0.0669367\ttotal: 5m 50s\tremaining: 6m 32s\n",
      "297:\tlearn: 0.0669326\ttotal: 5m 50s\tremaining: 6m 30s\n",
      "298:\tlearn: 0.0669282\ttotal: 5m 51s\tremaining: 6m 28s\n",
      "299:\tlearn: 0.0669267\ttotal: 5m 51s\tremaining: 6m 27s\n",
      "300:\tlearn: 0.0669255\ttotal: 5m 52s\tremaining: 6m 25s\n",
      "301:\tlearn: 0.0669247\ttotal: 5m 53s\tremaining: 6m 23s\n",
      "302:\tlearn: 0.0669225\ttotal: 5m 54s\tremaining: 6m 22s\n",
      "303:\tlearn: 0.0669184\ttotal: 5m 54s\tremaining: 6m 20s\n",
      "304:\tlearn: 0.0669150\ttotal: 5m 55s\tremaining: 6m 18s\n",
      "305:\tlearn: 0.0669106\ttotal: 5m 56s\tremaining: 6m 17s\n",
      "306:\tlearn: 0.0669076\ttotal: 5m 57s\tremaining: 6m 16s\n",
      "307:\tlearn: 0.0669053\ttotal: 5m 58s\tremaining: 6m 14s\n",
      "308:\tlearn: 0.0669007\ttotal: 5m 58s\tremaining: 6m 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309:\tlearn: 0.0668972\ttotal: 5m 59s\tremaining: 6m 11s\n",
      "310:\tlearn: 0.0668950\ttotal: 6m\tremaining: 6m 9s\n",
      "311:\tlearn: 0.0668933\ttotal: 6m 1s\tremaining: 6m 8s\n",
      "312:\tlearn: 0.0668911\ttotal: 6m 2s\tremaining: 6m 6s\n",
      "313:\tlearn: 0.0668904\ttotal: 6m 2s\tremaining: 6m 5s\n",
      "314:\tlearn: 0.0668882\ttotal: 6m 3s\tremaining: 6m 3s\n",
      "315:\tlearn: 0.0668848\ttotal: 6m 5s\tremaining: 6m 2s\n",
      "316:\tlearn: 0.0668822\ttotal: 6m 6s\tremaining: 6m 1s\n",
      "317:\tlearn: 0.0668781\ttotal: 6m 7s\tremaining: 6m\n",
      "318:\tlearn: 0.0668745\ttotal: 6m 8s\tremaining: 5m 59s\n",
      "319:\tlearn: 0.0668738\ttotal: 6m 9s\tremaining: 5m 58s\n",
      "320:\tlearn: 0.0668710\ttotal: 6m 10s\tremaining: 5m 56s\n",
      "321:\tlearn: 0.0668679\ttotal: 6m 11s\tremaining: 5m 55s\n",
      "322:\tlearn: 0.0668654\ttotal: 6m 12s\tremaining: 5m 53s\n",
      "323:\tlearn: 0.0668631\ttotal: 6m 13s\tremaining: 5m 52s\n",
      "324:\tlearn: 0.0668599\ttotal: 6m 14s\tremaining: 5m 51s\n",
      "325:\tlearn: 0.0668554\ttotal: 6m 15s\tremaining: 5m 50s\n",
      "326:\tlearn: 0.0668538\ttotal: 6m 16s\tremaining: 5m 48s\n",
      "327:\tlearn: 0.0668497\ttotal: 6m 16s\tremaining: 5m 47s\n",
      "328:\tlearn: 0.0668462\ttotal: 6m 17s\tremaining: 5m 45s\n",
      "329:\tlearn: 0.0668456\ttotal: 6m 18s\tremaining: 5m 44s\n",
      "330:\tlearn: 0.0668416\ttotal: 6m 18s\tremaining: 5m 42s\n",
      "331:\tlearn: 0.0668395\ttotal: 6m 19s\tremaining: 5m 40s\n",
      "332:\tlearn: 0.0668367\ttotal: 6m 20s\tremaining: 5m 39s\n",
      "333:\tlearn: 0.0668351\ttotal: 6m 20s\tremaining: 5m 37s\n",
      "334:\tlearn: 0.0668333\ttotal: 6m 21s\tremaining: 5m 35s\n",
      "335:\tlearn: 0.0668294\ttotal: 6m 21s\tremaining: 5m 34s\n",
      "336:\tlearn: 0.0668279\ttotal: 6m 22s\tremaining: 5m 32s\n",
      "337:\tlearn: 0.0668255\ttotal: 6m 23s\tremaining: 5m 31s\n",
      "338:\tlearn: 0.0668227\ttotal: 6m 23s\tremaining: 5m 29s\n",
      "339:\tlearn: 0.0668210\ttotal: 6m 24s\tremaining: 5m 27s\n",
      "340:\tlearn: 0.0668172\ttotal: 6m 25s\tremaining: 5m 26s\n",
      "341:\tlearn: 0.0668152\ttotal: 6m 25s\tremaining: 5m 24s\n",
      "342:\tlearn: 0.0668136\ttotal: 6m 26s\tremaining: 5m 23s\n",
      "343:\tlearn: 0.0668106\ttotal: 6m 26s\tremaining: 5m 21s\n",
      "344:\tlearn: 0.0668079\ttotal: 6m 27s\tremaining: 5m 19s\n",
      "345:\tlearn: 0.0668071\ttotal: 6m 27s\tremaining: 5m 18s\n",
      "346:\tlearn: 0.0668062\ttotal: 6m 28s\tremaining: 5m 16s\n",
      "347:\tlearn: 0.0668043\ttotal: 6m 29s\tremaining: 5m 15s\n",
      "348:\tlearn: 0.0668028\ttotal: 6m 29s\tremaining: 5m 13s\n",
      "349:\tlearn: 0.0668010\ttotal: 6m 30s\tremaining: 5m 12s\n",
      "350:\tlearn: 0.0667983\ttotal: 6m 31s\tremaining: 5m 10s\n",
      "351:\tlearn: 0.0667957\ttotal: 6m 31s\tremaining: 5m 9s\n",
      "352:\tlearn: 0.0667932\ttotal: 6m 32s\tremaining: 5m 7s\n",
      "353:\tlearn: 0.0667910\ttotal: 6m 33s\tremaining: 5m 6s\n",
      "354:\tlearn: 0.0667871\ttotal: 6m 33s\tremaining: 5m 5s\n",
      "355:\tlearn: 0.0667819\ttotal: 6m 34s\tremaining: 5m 3s\n",
      "356:\tlearn: 0.0667799\ttotal: 6m 34s\tremaining: 5m 2s\n",
      "357:\tlearn: 0.0667788\ttotal: 6m 35s\tremaining: 5m\n",
      "358:\tlearn: 0.0667770\ttotal: 6m 36s\tremaining: 4m 59s\n",
      "359:\tlearn: 0.0667761\ttotal: 6m 36s\tremaining: 4m 57s\n",
      "360:\tlearn: 0.0667742\ttotal: 6m 37s\tremaining: 4m 56s\n",
      "361:\tlearn: 0.0667716\ttotal: 6m 37s\tremaining: 4m 54s\n",
      "362:\tlearn: 0.0667680\ttotal: 6m 38s\tremaining: 4m 53s\n",
      "363:\tlearn: 0.0667654\ttotal: 6m 39s\tremaining: 4m 51s\n",
      "364:\tlearn: 0.0667639\ttotal: 6m 39s\tremaining: 4m 50s\n",
      "365:\tlearn: 0.0667623\ttotal: 6m 40s\tremaining: 4m 48s\n",
      "366:\tlearn: 0.0667598\ttotal: 6m 41s\tremaining: 4m 47s\n",
      "367:\tlearn: 0.0667561\ttotal: 6m 41s\tremaining: 4m 46s\n",
      "368:\tlearn: 0.0667523\ttotal: 6m 42s\tremaining: 4m 44s\n",
      "369:\tlearn: 0.0667486\ttotal: 6m 42s\tremaining: 4m 43s\n",
      "370:\tlearn: 0.0667464\ttotal: 6m 43s\tremaining: 4m 41s\n",
      "371:\tlearn: 0.0667408\ttotal: 6m 44s\tremaining: 4m 40s\n",
      "372:\tlearn: 0.0667392\ttotal: 6m 44s\tremaining: 4m 38s\n",
      "373:\tlearn: 0.0667378\ttotal: 6m 45s\tremaining: 4m 37s\n",
      "374:\tlearn: 0.0667368\ttotal: 6m 46s\tremaining: 4m 36s\n",
      "375:\tlearn: 0.0667333\ttotal: 6m 46s\tremaining: 4m 34s\n",
      "376:\tlearn: 0.0667319\ttotal: 6m 47s\tremaining: 4m 33s\n",
      "377:\tlearn: 0.0667304\ttotal: 6m 48s\tremaining: 4m 32s\n",
      "378:\tlearn: 0.0667291\ttotal: 6m 48s\tremaining: 4m 30s\n",
      "379:\tlearn: 0.0667264\ttotal: 6m 49s\tremaining: 4m 29s\n",
      "380:\tlearn: 0.0667240\ttotal: 6m 49s\tremaining: 4m 27s\n",
      "381:\tlearn: 0.0667221\ttotal: 6m 50s\tremaining: 4m 26s\n",
      "382:\tlearn: 0.0667206\ttotal: 6m 51s\tremaining: 4m 25s\n",
      "383:\tlearn: 0.0667172\ttotal: 6m 51s\tremaining: 4m 23s\n",
      "384:\tlearn: 0.0667140\ttotal: 6m 52s\tremaining: 4m 22s\n",
      "385:\tlearn: 0.0667128\ttotal: 6m 52s\tremaining: 4m 21s\n",
      "386:\tlearn: 0.0667093\ttotal: 6m 53s\tremaining: 4m 19s\n",
      "387:\tlearn: 0.0667069\ttotal: 6m 54s\tremaining: 4m 18s\n",
      "388:\tlearn: 0.0667033\ttotal: 6m 54s\tremaining: 4m 16s\n",
      "389:\tlearn: 0.0667016\ttotal: 6m 55s\tremaining: 4m 15s\n",
      "390:\tlearn: 0.0666978\ttotal: 6m 55s\tremaining: 4m 14s\n",
      "391:\tlearn: 0.0666954\ttotal: 6m 56s\tremaining: 4m 12s\n",
      "392:\tlearn: 0.0666913\ttotal: 6m 57s\tremaining: 4m 11s\n",
      "393:\tlearn: 0.0666892\ttotal: 6m 57s\tremaining: 4m 10s\n",
      "394:\tlearn: 0.0666878\ttotal: 6m 58s\tremaining: 4m 8s\n",
      "395:\tlearn: 0.0666841\ttotal: 6m 58s\tremaining: 4m 7s\n",
      "396:\tlearn: 0.0666812\ttotal: 6m 59s\tremaining: 4m 6s\n",
      "397:\tlearn: 0.0666789\ttotal: 7m\tremaining: 4m 4s\n",
      "398:\tlearn: 0.0666746\ttotal: 7m\tremaining: 4m 3s\n",
      "399:\tlearn: 0.0666729\ttotal: 7m 1s\tremaining: 4m 2s\n",
      "400:\tlearn: 0.0666701\ttotal: 7m 1s\tremaining: 4m\n",
      "401:\tlearn: 0.0666684\ttotal: 7m 2s\tremaining: 3m 59s\n",
      "402:\tlearn: 0.0666673\ttotal: 7m 3s\tremaining: 3m 58s\n",
      "403:\tlearn: 0.0666642\ttotal: 7m 3s\tremaining: 3m 57s\n",
      "404:\tlearn: 0.0666619\ttotal: 7m 4s\tremaining: 3m 55s\n",
      "405:\tlearn: 0.0666600\ttotal: 7m 4s\tremaining: 3m 54s\n",
      "406:\tlearn: 0.0666583\ttotal: 7m 5s\tremaining: 3m 53s\n",
      "407:\tlearn: 0.0666564\ttotal: 7m 6s\tremaining: 3m 51s\n",
      "408:\tlearn: 0.0666536\ttotal: 7m 6s\tremaining: 3m 50s\n",
      "409:\tlearn: 0.0666524\ttotal: 7m 7s\tremaining: 3m 49s\n",
      "410:\tlearn: 0.0666517\ttotal: 7m 8s\tremaining: 3m 48s\n",
      "411:\tlearn: 0.0666507\ttotal: 7m 9s\tremaining: 3m 47s\n",
      "412:\tlearn: 0.0666481\ttotal: 7m 9s\tremaining: 3m 45s\n",
      "413:\tlearn: 0.0666473\ttotal: 7m 10s\tremaining: 3m 44s\n",
      "414:\tlearn: 0.0666461\ttotal: 7m 11s\tremaining: 3m 43s\n",
      "415:\tlearn: 0.0666446\ttotal: 7m 13s\tremaining: 3m 42s\n",
      "416:\tlearn: 0.0666406\ttotal: 7m 13s\tremaining: 3m 41s\n",
      "417:\tlearn: 0.0666384\ttotal: 7m 14s\tremaining: 3m 40s\n",
      "418:\tlearn: 0.0666370\ttotal: 7m 15s\tremaining: 3m 39s\n",
      "419:\tlearn: 0.0666361\ttotal: 7m 16s\tremaining: 3m 38s\n",
      "420:\tlearn: 0.0666342\ttotal: 7m 17s\tremaining: 3m 37s\n",
      "421:\tlearn: 0.0666316\ttotal: 7m 17s\tremaining: 3m 35s\n",
      "422:\tlearn: 0.0666307\ttotal: 7m 19s\tremaining: 3m 34s\n",
      "423:\tlearn: 0.0666279\ttotal: 7m 22s\tremaining: 3m 35s\n",
      "424:\tlearn: 0.0666237\ttotal: 7m 25s\tremaining: 3m 34s\n",
      "425:\tlearn: 0.0666199\ttotal: 7m 28s\tremaining: 3m 34s\n",
      "426:\tlearn: 0.0666178\ttotal: 7m 29s\tremaining: 3m 33s\n",
      "427:\tlearn: 0.0666163\ttotal: 7m 30s\tremaining: 3m 32s\n",
      "428:\tlearn: 0.0666124\ttotal: 7m 31s\tremaining: 3m 31s\n",
      "429:\tlearn: 0.0666109\ttotal: 7m 32s\tremaining: 3m 30s\n",
      "430:\tlearn: 0.0666090\ttotal: 7m 34s\tremaining: 3m 29s\n",
      "431:\tlearn: 0.0666074\ttotal: 7m 35s\tremaining: 3m 28s\n",
      "432:\tlearn: 0.0666055\ttotal: 7m 36s\tremaining: 3m 27s\n",
      "433:\tlearn: 0.0666028\ttotal: 7m 36s\tremaining: 3m 26s\n",
      "434:\tlearn: 0.0666013\ttotal: 7m 37s\tremaining: 3m 25s\n",
      "435:\tlearn: 0.0665981\ttotal: 7m 38s\tremaining: 3m 23s\n",
      "436:\tlearn: 0.0665949\ttotal: 7m 38s\tremaining: 3m 22s\n",
      "437:\tlearn: 0.0665929\ttotal: 7m 39s\tremaining: 3m 21s\n",
      "438:\tlearn: 0.0665919\ttotal: 7m 40s\tremaining: 3m 20s\n",
      "439:\tlearn: 0.0665895\ttotal: 7m 40s\tremaining: 3m 18s\n",
      "440:\tlearn: 0.0665890\ttotal: 7m 41s\tremaining: 3m 17s\n",
      "441:\tlearn: 0.0665870\ttotal: 7m 41s\tremaining: 3m 16s\n",
      "442:\tlearn: 0.0665827\ttotal: 7m 42s\tremaining: 3m 15s\n",
      "443:\tlearn: 0.0665804\ttotal: 7m 43s\tremaining: 3m 13s\n",
      "444:\tlearn: 0.0665792\ttotal: 7m 43s\tremaining: 3m 12s\n",
      "445:\tlearn: 0.0665785\ttotal: 7m 44s\tremaining: 3m 11s\n",
      "446:\tlearn: 0.0665753\ttotal: 7m 44s\tremaining: 3m 10s\n",
      "447:\tlearn: 0.0665718\ttotal: 7m 45s\tremaining: 3m 9s\n",
      "448:\tlearn: 0.0665707\ttotal: 7m 46s\tremaining: 3m 7s\n",
      "449:\tlearn: 0.0665681\ttotal: 7m 46s\tremaining: 3m 6s\n",
      "450:\tlearn: 0.0665670\ttotal: 7m 47s\tremaining: 3m 5s\n",
      "451:\tlearn: 0.0665646\ttotal: 7m 48s\tremaining: 3m 4s\n",
      "452:\tlearn: 0.0665621\ttotal: 7m 48s\tremaining: 3m 3s\n",
      "453:\tlearn: 0.0665600\ttotal: 7m 49s\tremaining: 3m 2s\n",
      "454:\tlearn: 0.0665590\ttotal: 7m 50s\tremaining: 3m\n",
      "455:\tlearn: 0.0665580\ttotal: 7m 51s\tremaining: 2m 59s\n",
      "456:\tlearn: 0.0665561\ttotal: 7m 51s\tremaining: 2m 58s\n",
      "457:\tlearn: 0.0665519\ttotal: 7m 52s\tremaining: 2m 57s\n",
      "458:\tlearn: 0.0665485\ttotal: 7m 53s\tremaining: 2m 56s\n",
      "459:\tlearn: 0.0665445\ttotal: 7m 53s\tremaining: 2m 55s\n",
      "460:\tlearn: 0.0665435\ttotal: 7m 54s\tremaining: 2m 53s\n",
      "461:\tlearn: 0.0665411\ttotal: 7m 54s\tremaining: 2m 52s\n",
      "462:\tlearn: 0.0665403\ttotal: 7m 55s\tremaining: 2m 51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463:\tlearn: 0.0665387\ttotal: 7m 56s\tremaining: 2m 50s\n",
      "464:\tlearn: 0.0665367\ttotal: 7m 56s\tremaining: 2m 49s\n",
      "465:\tlearn: 0.0665361\ttotal: 7m 57s\tremaining: 2m 48s\n",
      "466:\tlearn: 0.0665345\ttotal: 7m 58s\tremaining: 2m 46s\n",
      "467:\tlearn: 0.0665329\ttotal: 7m 58s\tremaining: 2m 45s\n",
      "468:\tlearn: 0.0665318\ttotal: 7m 59s\tremaining: 2m 44s\n",
      "469:\tlearn: 0.0665303\ttotal: 7m 59s\tremaining: 2m 43s\n",
      "470:\tlearn: 0.0665278\ttotal: 8m\tremaining: 2m 42s\n",
      "471:\tlearn: 0.0665233\ttotal: 8m 1s\tremaining: 2m 41s\n",
      "472:\tlearn: 0.0665195\ttotal: 8m 1s\tremaining: 2m 39s\n",
      "473:\tlearn: 0.0665170\ttotal: 8m 2s\tremaining: 2m 38s\n",
      "474:\tlearn: 0.0665130\ttotal: 8m 2s\tremaining: 2m 37s\n",
      "475:\tlearn: 0.0665098\ttotal: 8m 3s\tremaining: 2m 36s\n",
      "476:\tlearn: 0.0665085\ttotal: 8m 4s\tremaining: 2m 35s\n",
      "477:\tlearn: 0.0665059\ttotal: 8m 4s\tremaining: 2m 34s\n",
      "478:\tlearn: 0.0665052\ttotal: 8m 5s\tremaining: 2m 32s\n",
      "479:\tlearn: 0.0665035\ttotal: 8m 5s\tremaining: 2m 31s\n",
      "480:\tlearn: 0.0664999\ttotal: 8m 6s\tremaining: 2m 30s\n",
      "481:\tlearn: 0.0664989\ttotal: 8m 7s\tremaining: 2m 29s\n",
      "482:\tlearn: 0.0664974\ttotal: 8m 7s\tremaining: 2m 28s\n",
      "483:\tlearn: 0.0664949\ttotal: 8m 8s\tremaining: 2m 27s\n",
      "484:\tlearn: 0.0664939\ttotal: 8m 8s\tremaining: 2m 26s\n",
      "485:\tlearn: 0.0664917\ttotal: 8m 9s\tremaining: 2m 25s\n",
      "486:\tlearn: 0.0664915\ttotal: 8m 10s\tremaining: 2m 23s\n",
      "487:\tlearn: 0.0664892\ttotal: 8m 10s\tremaining: 2m 22s\n",
      "488:\tlearn: 0.0664864\ttotal: 8m 11s\tremaining: 2m 21s\n",
      "489:\tlearn: 0.0664851\ttotal: 8m 12s\tremaining: 2m 20s\n",
      "490:\tlearn: 0.0664840\ttotal: 8m 12s\tremaining: 2m 19s\n",
      "491:\tlearn: 0.0664816\ttotal: 8m 13s\tremaining: 2m 18s\n",
      "492:\tlearn: 0.0664798\ttotal: 8m 13s\tremaining: 2m 17s\n",
      "493:\tlearn: 0.0664784\ttotal: 8m 14s\tremaining: 2m 16s\n",
      "494:\tlearn: 0.0664761\ttotal: 8m 15s\tremaining: 2m 15s\n",
      "495:\tlearn: 0.0664750\ttotal: 8m 16s\tremaining: 2m 14s\n",
      "496:\tlearn: 0.0664726\ttotal: 8m 17s\tremaining: 2m 13s\n",
      "497:\tlearn: 0.0664705\ttotal: 8m 18s\tremaining: 2m 12s\n",
      "498:\tlearn: 0.0664699\ttotal: 8m 18s\tremaining: 2m 10s\n",
      "499:\tlearn: 0.0664682\ttotal: 8m 19s\tremaining: 2m 9s\n",
      "500:\tlearn: 0.0664668\ttotal: 8m 20s\tremaining: 2m 8s\n",
      "501:\tlearn: 0.0664647\ttotal: 8m 21s\tremaining: 2m 7s\n",
      "502:\tlearn: 0.0664634\ttotal: 8m 21s\tremaining: 2m 6s\n",
      "503:\tlearn: 0.0664623\ttotal: 8m 22s\tremaining: 2m 5s\n",
      "504:\tlearn: 0.0664613\ttotal: 8m 23s\tremaining: 2m 4s\n",
      "505:\tlearn: 0.0664602\ttotal: 8m 23s\tremaining: 2m 3s\n",
      "506:\tlearn: 0.0664572\ttotal: 8m 24s\tremaining: 2m 2s\n",
      "507:\tlearn: 0.0664531\ttotal: 8m 24s\tremaining: 2m 1s\n",
      "508:\tlearn: 0.0664514\ttotal: 8m 25s\tremaining: 2m\n",
      "509:\tlearn: 0.0664504\ttotal: 8m 25s\tremaining: 1m 59s\n",
      "510:\tlearn: 0.0664491\ttotal: 8m 26s\tremaining: 1m 57s\n",
      "511:\tlearn: 0.0664481\ttotal: 8m 27s\tremaining: 1m 56s\n",
      "512:\tlearn: 0.0664474\ttotal: 8m 27s\tremaining: 1m 55s\n",
      "513:\tlearn: 0.0664459\ttotal: 8m 28s\tremaining: 1m 54s\n",
      "514:\tlearn: 0.0664442\ttotal: 8m 29s\tremaining: 1m 53s\n",
      "515:\tlearn: 0.0664424\ttotal: 8m 29s\tremaining: 1m 52s\n",
      "516:\tlearn: 0.0664407\ttotal: 8m 30s\tremaining: 1m 51s\n",
      "517:\tlearn: 0.0664367\ttotal: 8m 31s\tremaining: 1m 50s\n",
      "518:\tlearn: 0.0664345\ttotal: 8m 31s\tremaining: 1m 49s\n",
      "519:\tlearn: 0.0664322\ttotal: 8m 32s\tremaining: 1m 48s\n",
      "520:\tlearn: 0.0664288\ttotal: 8m 32s\tremaining: 1m 47s\n",
      "521:\tlearn: 0.0664276\ttotal: 8m 33s\tremaining: 1m 46s\n",
      "522:\tlearn: 0.0664267\ttotal: 8m 33s\tremaining: 1m 45s\n",
      "523:\tlearn: 0.0664239\ttotal: 8m 34s\tremaining: 1m 44s\n",
      "524:\tlearn: 0.0664205\ttotal: 8m 35s\tremaining: 1m 43s\n",
      "525:\tlearn: 0.0664182\ttotal: 8m 36s\tremaining: 1m 42s\n",
      "526:\tlearn: 0.0664164\ttotal: 8m 36s\tremaining: 1m 41s\n",
      "527:\tlearn: 0.0664141\ttotal: 8m 37s\tremaining: 1m 39s\n",
      "528:\tlearn: 0.0664121\ttotal: 8m 38s\tremaining: 1m 38s\n",
      "529:\tlearn: 0.0664106\ttotal: 8m 38s\tremaining: 1m 37s\n",
      "530:\tlearn: 0.0664094\ttotal: 8m 39s\tremaining: 1m 36s\n",
      "531:\tlearn: 0.0664073\ttotal: 8m 39s\tremaining: 1m 35s\n",
      "532:\tlearn: 0.0664058\ttotal: 8m 40s\tremaining: 1m 34s\n",
      "533:\tlearn: 0.0664035\ttotal: 8m 41s\tremaining: 1m 33s\n",
      "534:\tlearn: 0.0663999\ttotal: 8m 41s\tremaining: 1m 32s\n",
      "535:\tlearn: 0.0663976\ttotal: 8m 42s\tremaining: 1m 31s\n",
      "536:\tlearn: 0.0663967\ttotal: 8m 42s\tremaining: 1m 30s\n",
      "537:\tlearn: 0.0663943\ttotal: 8m 43s\tremaining: 1m 29s\n",
      "538:\tlearn: 0.0663925\ttotal: 8m 44s\tremaining: 1m 28s\n",
      "539:\tlearn: 0.0663914\ttotal: 8m 44s\tremaining: 1m 27s\n",
      "540:\tlearn: 0.0663881\ttotal: 8m 45s\tremaining: 1m 26s\n",
      "541:\tlearn: 0.0663873\ttotal: 8m 46s\tremaining: 1m 25s\n",
      "542:\tlearn: 0.0663860\ttotal: 8m 46s\tremaining: 1m 24s\n",
      "543:\tlearn: 0.0663852\ttotal: 8m 47s\tremaining: 1m 23s\n",
      "544:\tlearn: 0.0663841\ttotal: 8m 47s\tremaining: 1m 22s\n",
      "545:\tlearn: 0.0663826\ttotal: 8m 48s\tremaining: 1m 21s\n",
      "546:\tlearn: 0.0663809\ttotal: 8m 49s\tremaining: 1m 20s\n",
      "547:\tlearn: 0.0663788\ttotal: 8m 49s\tremaining: 1m 19s\n",
      "548:\tlearn: 0.0663774\ttotal: 8m 50s\tremaining: 1m 18s\n",
      "549:\tlearn: 0.0663763\ttotal: 8m 50s\tremaining: 1m 17s\n",
      "550:\tlearn: 0.0663751\ttotal: 8m 51s\tremaining: 1m 16s\n",
      "551:\tlearn: 0.0663730\ttotal: 8m 52s\tremaining: 1m 15s\n",
      "552:\tlearn: 0.0663720\ttotal: 8m 52s\tremaining: 1m 14s\n",
      "553:\tlearn: 0.0663707\ttotal: 8m 53s\tremaining: 1m 13s\n",
      "554:\tlearn: 0.0663691\ttotal: 8m 53s\tremaining: 1m 12s\n",
      "555:\tlearn: 0.0663673\ttotal: 8m 54s\tremaining: 1m 11s\n",
      "556:\tlearn: 0.0663664\ttotal: 8m 55s\tremaining: 1m 10s\n",
      "557:\tlearn: 0.0663659\ttotal: 8m 55s\tremaining: 1m 9s\n",
      "558:\tlearn: 0.0663648\ttotal: 8m 56s\tremaining: 1m 8s\n",
      "559:\tlearn: 0.0663638\ttotal: 8m 56s\tremaining: 1m 7s\n",
      "560:\tlearn: 0.0663618\ttotal: 8m 57s\tremaining: 1m 6s\n",
      "561:\tlearn: 0.0663595\ttotal: 8m 58s\tremaining: 1m 5s\n",
      "562:\tlearn: 0.0663571\ttotal: 8m 58s\tremaining: 1m 4s\n",
      "563:\tlearn: 0.0663564\ttotal: 8m 59s\tremaining: 1m 3s\n",
      "564:\tlearn: 0.0663534\ttotal: 9m\tremaining: 1m 2s\n",
      "565:\tlearn: 0.0663511\ttotal: 9m 1s\tremaining: 1m 1s\n",
      "566:\tlearn: 0.0663499\ttotal: 9m 2s\tremaining: 1m\n",
      "567:\tlearn: 0.0663458\ttotal: 9m 3s\tremaining: 59.3s\n",
      "568:\tlearn: 0.0663443\ttotal: 9m 3s\tremaining: 58.3s\n",
      "569:\tlearn: 0.0663406\ttotal: 9m 4s\tremaining: 57.3s\n",
      "570:\tlearn: 0.0663367\ttotal: 9m 5s\tremaining: 56.3s\n",
      "571:\tlearn: 0.0663342\ttotal: 9m 5s\tremaining: 55.4s\n",
      "572:\tlearn: 0.0663325\ttotal: 9m 6s\tremaining: 54.4s\n",
      "573:\tlearn: 0.0663310\ttotal: 9m 7s\tremaining: 53.4s\n",
      "574:\tlearn: 0.0663290\ttotal: 9m 7s\tremaining: 52.4s\n",
      "575:\tlearn: 0.0663266\ttotal: 9m 8s\tremaining: 51.4s\n",
      "576:\tlearn: 0.0663243\ttotal: 9m 9s\tremaining: 50.4s\n",
      "577:\tlearn: 0.0663229\ttotal: 9m 10s\tremaining: 49.5s\n",
      "578:\tlearn: 0.0663203\ttotal: 9m 11s\tremaining: 48.5s\n",
      "579:\tlearn: 0.0663161\ttotal: 9m 12s\tremaining: 47.6s\n",
      "580:\tlearn: 0.0663149\ttotal: 9m 13s\tremaining: 46.6s\n",
      "581:\tlearn: 0.0663138\ttotal: 9m 13s\tremaining: 45.7s\n",
      "582:\tlearn: 0.0663125\ttotal: 9m 14s\tremaining: 44.7s\n",
      "583:\tlearn: 0.0663103\ttotal: 9m 15s\tremaining: 43.8s\n",
      "584:\tlearn: 0.0663065\ttotal: 9m 16s\tremaining: 42.8s\n",
      "585:\tlearn: 0.0663038\ttotal: 9m 17s\tremaining: 41.9s\n",
      "586:\tlearn: 0.0663033\ttotal: 9m 18s\tremaining: 40.9s\n",
      "587:\tlearn: 0.0663011\ttotal: 9m 19s\tremaining: 40s\n",
      "588:\tlearn: 0.0663007\ttotal: 9m 19s\tremaining: 39s\n",
      "589:\tlearn: 0.0663005\ttotal: 9m 20s\tremaining: 38s\n",
      "590:\tlearn: 0.0662998\ttotal: 9m 21s\tremaining: 37s\n",
      "591:\tlearn: 0.0662994\ttotal: 9m 21s\tremaining: 36.1s\n",
      "592:\tlearn: 0.0662981\ttotal: 9m 22s\tremaining: 35.1s\n",
      "593:\tlearn: 0.0662957\ttotal: 9m 22s\tremaining: 34.1s\n",
      "594:\tlearn: 0.0662944\ttotal: 9m 23s\tremaining: 33.1s\n",
      "595:\tlearn: 0.0662930\ttotal: 9m 24s\tremaining: 32.2s\n",
      "596:\tlearn: 0.0662918\ttotal: 9m 24s\tremaining: 31.2s\n",
      "597:\tlearn: 0.0662874\ttotal: 9m 25s\tremaining: 30.2s\n",
      "598:\tlearn: 0.0662849\ttotal: 9m 25s\tremaining: 29.3s\n",
      "599:\tlearn: 0.0662827\ttotal: 9m 26s\tremaining: 28.3s\n",
      "600:\tlearn: 0.0662809\ttotal: 9m 27s\tremaining: 27.4s\n",
      "601:\tlearn: 0.0662787\ttotal: 9m 27s\tremaining: 26.4s\n",
      "602:\tlearn: 0.0662757\ttotal: 9m 28s\tremaining: 25.4s\n",
      "603:\tlearn: 0.0662713\ttotal: 9m 28s\tremaining: 24.5s\n",
      "604:\tlearn: 0.0662691\ttotal: 9m 29s\tremaining: 23.5s\n",
      "605:\tlearn: 0.0662652\ttotal: 9m 30s\tremaining: 22.6s\n",
      "606:\tlearn: 0.0662608\ttotal: 9m 30s\tremaining: 21.6s\n",
      "607:\tlearn: 0.0662596\ttotal: 9m 31s\tremaining: 20.7s\n",
      "608:\tlearn: 0.0662584\ttotal: 9m 32s\tremaining: 19.7s\n",
      "609:\tlearn: 0.0662579\ttotal: 9m 32s\tremaining: 18.8s\n",
      "610:\tlearn: 0.0662558\ttotal: 9m 33s\tremaining: 17.8s\n",
      "611:\tlearn: 0.0662533\ttotal: 9m 34s\tremaining: 16.9s\n",
      "612:\tlearn: 0.0662516\ttotal: 9m 34s\tremaining: 15.9s\n",
      "613:\tlearn: 0.0662492\ttotal: 9m 35s\tremaining: 15s\n",
      "614:\tlearn: 0.0662453\ttotal: 9m 36s\tremaining: 14.1s\n",
      "615:\tlearn: 0.0662436\ttotal: 9m 37s\tremaining: 13.1s\n",
      "616:\tlearn: 0.0662426\ttotal: 9m 38s\tremaining: 12.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617:\tlearn: 0.0662416\ttotal: 9m 39s\tremaining: 11.2s\n",
      "618:\tlearn: 0.0662406\ttotal: 9m 40s\tremaining: 10.3s\n",
      "619:\tlearn: 0.0662393\ttotal: 9m 41s\tremaining: 9.38s\n",
      "620:\tlearn: 0.0662378\ttotal: 9m 42s\tremaining: 8.44s\n",
      "621:\tlearn: 0.0662370\ttotal: 9m 43s\tremaining: 7.51s\n",
      "622:\tlearn: 0.0662355\ttotal: 9m 44s\tremaining: 6.57s\n",
      "623:\tlearn: 0.0662341\ttotal: 9m 45s\tremaining: 5.63s\n",
      "624:\tlearn: 0.0662331\ttotal: 9m 46s\tremaining: 4.69s\n",
      "625:\tlearn: 0.0662317\ttotal: 9m 47s\tremaining: 3.75s\n",
      "626:\tlearn: 0.0662278\ttotal: 9m 48s\tremaining: 2.81s\n",
      "627:\tlearn: 0.0662257\ttotal: 9m 49s\tremaining: 1.88s\n",
      "628:\tlearn: 0.0662250\ttotal: 9m 49s\tremaining: 938ms\n",
      "629:\tlearn: 0.0662240\ttotal: 9m 50s\tremaining: 0us\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3965b73019f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     model.fit(\n\u001b[1;32m     11\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         cat_features=cat_feature_inds)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_ensembles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval)\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \"\"\"\n\u001b[0;32m-> 2005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mtrain_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_train_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_feature_importance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_classification_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mget_feature_importance\u001b[0;34m(self, data, thread_count, fstr_type)\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0mfstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_fstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstr_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m         \u001b[0mfstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_fstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstr_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfstr_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FeatureImportance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_ensembles = 5\n",
    "y_pred = 0.0\n",
    "for i in tqdm(range(num_ensembles)):\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=630, learning_rate=0.03,\n",
    "        depth=6, l2_leaf_reg=3,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=i)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features=cat_feature_inds)\n",
    "    y_pred += model.predict(X_test)\n",
    "y_pred /= num_ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM Parameter setting\n",
    "params = {}\n",
    "params['max_bin'] = 10\n",
    "params['learning_rate'] = 0.0021 # shrinkage_rate\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'l1'          # or 'mae'\n",
    "params['sub_feature'] = 0.5      # feature_fraction -- OK, back to .5, but maybe later increase this\n",
    "params['bagging_fraction'] = 0.85 # sub_row\n",
    "params['bagging_freq'] = 40\n",
    "params['num_leaves'] = 512        # num_leaf\n",
    "params['min_data'] = 500         # min_data_in_leaf\n",
    "params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\n",
    "params['verbose'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset for LightGBM\n",
    "d_train = lgb.Dataset(X_train, label=y_train_GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting LightGBM model ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields propertycountylandusecode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6049d48c50b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFitting LightGBM model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m430\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields propertycountylandusecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Need to check d_train, d_train is generate from X_train and y_train. Let's check if they are float, int or bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1307\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    858\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_has_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields propertycountylandusecode"
     ]
    }
   ],
   "source": [
    "print(\"\\nFitting LightGBM model ...\")\n",
    "clf = lgb.train(params, d_train, 430)  # DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields propertycountylandusecode\n",
    "# Need to check d_train, d_train is generate from X_train and y_train. Let's check if they are float, int or bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d_train; gc.collect()\n",
    "del x_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSetting up data for XGBoost ...\")\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_rounds = 242\n",
    "print(\"\\nXGBoost tuned with CV in:\")\n",
    "print(\"   https://www.kaggle.com/aharless/xgboost-without-outliers-tweak \")\n",
    "print(\"num_boost_rounds=\"+str(num_boost_rounds))\n",
    "\n",
    "# train model\n",
    "print( \"\\nTraining XGBoost ...\")\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "print( \"\\nPredicting with XGBoost ...\")\n",
    "xgb_pred = model.predict(dtest)\n",
    "\n",
    "print( \"\\nXGBoost predictions:\" )\n",
    "print( pd.DataFrame(xgb_pred).head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT\n",
    "pred = XGB_WEIGHT*xgb_pred + BASELINE_WEIGHT*BASELINE_PRED + lgb_weight*p_test\n",
    "\n",
    "print( \"\\nCombined predictions:\" )\n",
    "print( pd.DataFrame(pred).head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ParcelId': test_df['ParcelId'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = {\n",
    "    '201610': pd.Timestamp('2016-09-30'),\n",
    "    '201611': pd.Timestamp('2016-10-31'),\n",
    "    '201612': pd.Timestamp('2016-11-30'),\n",
    "    '201710': pd.Timestamp('2017-09-30'),\n",
    "    '201711': pd.Timestamp('2017-10-31'),\n",
    "    '201712': pd.Timestamp('2017-11-30')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, test_date in test_dates.items():\n",
    "    print(\"Predicting for: %s ... \" % (label))\n",
    "    submission[label] = y_pred\n",
    "    \n",
    "    \n",
    "submission.to_csv('Only_CatBoost.csv', float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
