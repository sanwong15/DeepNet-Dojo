{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data from disk ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data for LightGBM ...\n",
      "(90275, 53) (90275,)\n",
      "\n",
      "Fitting LightGBM model ...\n",
      "\n",
      "Prepare for LightGBM prediction ...\n",
      "   Read sample file ...\n",
      "   ...\n",
      "   Merge with property data ...\n",
      "   ...\n",
      "   ...\n",
      "   ...\n",
      "   Preparing x_test...\n",
      "   ...\n",
      "Test shape : (2985217, 53)\n",
      "\n",
      "Start LightGBM prediction ...\n",
      "\n",
      "Unadjusted LightGBM predictions:\n",
      "          0\n",
      "0  0.030537\n",
      "1  0.032548\n",
      "2  0.010753\n",
      "3  0.008473\n",
      "4  0.009224\n",
      "\n",
      "Re-reading properties file ...\n",
      "\n",
      "Processing data for XGBoost ...\n",
      "Shape train: (90275, 57)\n",
      "Shape test: (2985217, 57)\n",
      "After removing outliers:\n",
      "Shape train: (88528, 57)\n",
      "Shape test: (2985217, 57)\n",
      "\n",
      "Setting up data for XGBoost ...\n",
      "num_boost_rounds=250\n",
      "\n",
      "Training XGBoost ...\n",
      "\n",
      "Predicting with XGBoost ...\n",
      "\n",
      "First XGBoost predictions:\n",
      "          0\n",
      "0 -0.023582\n",
      "1 -0.032242\n",
      "2  0.007546\n",
      "3  0.064200\n",
      "4 -0.004868\n",
      "\n",
      "Setting up data for XGBoost ...\n",
      "num_boost_rounds=150\n",
      "\n",
      "Training XGBoost again ...\n",
      "\n",
      "Predicting with XGBoost again ...\n",
      "\n",
      "Second XGBoost predictions:\n",
      "          0\n",
      "0 -0.073580\n",
      "1 -0.010724\n",
      "2  0.030864\n",
      "3  0.078579\n",
      "4  0.022030\n",
      "\n",
      "Combined XGBoost predictions:\n",
      "          0\n",
      "0 -0.033166\n",
      "1 -0.028117\n",
      "2  0.012016\n",
      "3  0.066956\n",
      "4  0.000288\n",
      "90275 2985217 2985217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/Arical_Kaggle/lib/python3.6/site-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit...\n",
      "0.06837008433548178\n",
      "\n",
      "Combining XGBoost, LightGBM, and baseline predicitons ...\n",
      "\n",
      "Combined XGB/LGB/baseline predictions:\n",
      "          0\n",
      "0 -0.011378\n",
      "1 -0.007072\n",
      "2  0.012612\n",
      "3  0.050160\n",
      "4  0.003821\n",
      "\n",
      "Predicting with OLS and combining with XGB/LGB/baseline predicitons: ...\n",
      "predict... 0\n",
      "predict... 1\n",
      "predict... 2\n",
      "predict... 3\n",
      "predict... 4\n",
      "predict... 5\n",
      "\n",
      "Combined XGB/LGB/baseline/OLS predictions:\n",
      "   ParcelId  201610  201611  201612  201710  201711  201712\n",
      "0  10754147 -0.0132 -0.0132 -0.0132 -0.0132 -0.0132 -0.0132\n",
      "1  10759547 -0.0097 -0.0097 -0.0097 -0.0097 -0.0097 -0.0097\n",
      "2  10843547  0.0653  0.0653  0.0653  0.0653  0.0653  0.0653\n",
      "3  10859147  0.0492  0.0492  0.0492  0.0492  0.0492  0.0492\n",
      "4  10879947  0.0060  0.0060  0.0060  0.0060  0.0060  0.0060\n",
      "\n",
      "Writing results to disk ...\n",
      "\n",
      "Finished ...\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "################\n",
    "################\n",
    "##  LightGBM changes ##\n",
    "# V42 - sub_feature: 0.3 -> 0.35 : LB = 0.0643759\n",
    "# V34 - sub_feature: 0.5 -> 0.42\n",
    "# V33 - sub_feature: 0.5 -> 0.45 : LB = 0.0643866\n",
    "# - sub_feature: 0.45 -> 0.3 : LB = 0.0643811 / 0.0643814 \n",
    "################\n",
    "################ \n",
    "\n",
    "# Parameters\n",
    "XGB_WEIGHT = 0.6415\n",
    "BASELINE_WEIGHT = 0.0056\n",
    "OLS_WEIGHT = 0.0828\n",
    "\n",
    "XGB1_WEIGHT = 0.8083  # Weight of first in combination of two XGB models\n",
    "\n",
    "BASELINE_PRED = 0.0115   # Baseline based on mean of training data, per Oleg\n",
    "\n",
    "##### READ IN RAW DATA\n",
    "print( \"\\nReading data from disk ...\")\n",
    "prop = pd.read_csv('../input/properties_2016.csv')\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\")\n",
    "\n",
    "\n",
    "################\n",
    "################\n",
    "##  LightGBM  ##\n",
    "################\n",
    "################\n",
    "\n",
    "##### PROCESS DATA FOR LIGHTGBM\n",
    "print( \"\\nProcessing data for LightGBM ...\" )\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "df_train.fillna(df_train.median(),inplace = True)\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', \n",
    "                         'propertycountylandusecode', 'fireplacecnt', 'fireplaceflag'], axis=1)\n",
    "#x_train['Ratio_1'] = x_train['taxvaluedollarcnt']/x_train['taxamount']\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()\n",
    "\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "\n",
    "\n",
    "##### RUN LIGHTGBM\n",
    "params = {}\n",
    "params['max_bin'] = 10\n",
    "params['learning_rate'] = 0.0021 # shrinkage_rate\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'l1'          # or 'mae'\n",
    "params['sub_feature'] = 0.345    \n",
    "params['bagging_fraction'] = 0.85 # sub_row\n",
    "params['bagging_freq'] = 40\n",
    "params['num_leaves'] = 512        # num_leaf\n",
    "params['min_data'] = 500         # min_data_in_leaf\n",
    "params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\n",
    "params['verbose'] = 0\n",
    "params['feature_fraction_seed'] = 2\n",
    "params['bagging_seed'] = 3\n",
    "\n",
    "print(\"\\nFitting LightGBM model ...\")\n",
    "clf = lgb.train(params, d_train, 430)\n",
    "\n",
    "del d_train; gc.collect()\n",
    "del x_train; gc.collect()\n",
    "\n",
    "print(\"\\nPrepare for LightGBM prediction ...\")\n",
    "print(\"   Read sample file ...\")\n",
    "sample = pd.read_csv('../input/sample_submission.csv')\n",
    "print(\"   ...\")\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "print(\"   Merge with property data ...\")\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "print(\"   ...\")\n",
    "del sample, prop; gc.collect()\n",
    "print(\"   ...\")\n",
    "#df_test['Ratio_1'] = df_test['taxvaluedollarcnt']/df_test['taxamount']\n",
    "x_test = df_test[train_columns]\n",
    "print(\"   ...\")\n",
    "del df_test; gc.collect()\n",
    "print(\"   Preparing x_test...\")\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "print(\"   ...\")\n",
    "x_test = x_test.values.astype(np.float32, copy=False)\n",
    "print(\"Test shape :\", x_test.shape)\n",
    "\n",
    "print(\"\\nStart LightGBM prediction ...\")\n",
    "p_test = clf.predict(x_test)\n",
    "\n",
    "del x_test; gc.collect()\n",
    "\n",
    "print( \"\\nUnadjusted LightGBM predictions:\" )\n",
    "print( pd.DataFrame(p_test).head() )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "################\n",
    "##  XGBoost   ##\n",
    "################\n",
    "################\n",
    "\n",
    "##### RE-READ PROPERTIES FILE\n",
    "##### (I tried keeping a copy, but the program crashed.)\n",
    "\n",
    "print( \"\\nRe-reading properties file ...\")\n",
    "properties = pd.read_csv('../input/properties_2016.csv')\n",
    "\n",
    "##### PROCESS DATA FOR XGBOOST\n",
    "print( \"\\nProcessing data for XGBoost ...\")\n",
    "for c in properties.columns:\n",
    "    properties[c]=properties[c].fillna(-1)\n",
    "    if properties[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties[c].values))\n",
    "        properties[c] = lbl.transform(list(properties[c].values))\n",
    "\n",
    "train_df = train.merge(properties, how='left', on='parcelid')\n",
    "x_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "x_test = properties.drop(['parcelid'], axis=1)\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n",
    "\n",
    "# drop out ouliers\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "x_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "y_train = train_df[\"logerror\"].values.astype(np.float32)\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "print('After removing outliers:')     \n",
    "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### RUN XGBOOST\n",
    "print(\"\\nSetting up data for XGBoost ...\")\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "num_boost_rounds = 250\n",
    "print(\"num_boost_rounds=\"+str(num_boost_rounds))\n",
    "\n",
    "# train model\n",
    "print( \"\\nTraining XGBoost ...\")\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "print( \"\\nPredicting with XGBoost ...\")\n",
    "xgb_pred1 = model.predict(dtest)\n",
    "\n",
    "print( \"\\nFirst XGBoost predictions:\" )\n",
    "print( pd.DataFrame(xgb_pred1).head() )\n",
    "\n",
    "\n",
    "\n",
    "##### RUN XGBOOST AGAIN\n",
    "print(\"\\nSetting up data for XGBoost ...\")\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.033,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "num_boost_rounds = 150\n",
    "print(\"num_boost_rounds=\"+str(num_boost_rounds))\n",
    "\n",
    "print( \"\\nTraining XGBoost again ...\")\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n",
    "\n",
    "print( \"\\nPredicting with XGBoost again ...\")\n",
    "xgb_pred2 = model.predict(dtest)\n",
    "\n",
    "print( \"\\nSecond XGBoost predictions:\" )\n",
    "print( pd.DataFrame(xgb_pred2).head() )\n",
    "\n",
    "\n",
    "\n",
    "##### COMBINE XGBOOST RESULTS\n",
    "\n",
    "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n",
    "#xgb_pred = xgb_pred1\n",
    "\n",
    "print( \"\\nCombined XGBoost predictions:\" )\n",
    "print( pd.DataFrame(xgb_pred).head() )\n",
    "\n",
    "del train_df\n",
    "del x_train\n",
    "del x_test\n",
    "del properties\n",
    "del dtest\n",
    "del dtrain\n",
    "del xgb_pred1\n",
    "del xgb_pred2 \n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "################\n",
    "##    OLS     ##\n",
    "################\n",
    "################\n",
    "\n",
    "# This section is derived from the1owl's notebook:\n",
    "#    https://www.kaggle.com/the1owl/primer-for-the-zillow-pred-approach\n",
    "# which I (Andy Harless) updated and made into a script:\n",
    "#    https://www.kaggle.com/aharless/updated-script-version-of-the1owl-s-basic-ols\n",
    "np.random.seed(17)\n",
    "random.seed(17)\n",
    "\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "properties = pd.read_csv(\"../input/properties_2016.csv\")\n",
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "print(len(train),len(properties),len(submission))\n",
    "\n",
    "def get_features(df):\n",
    "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n",
    "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df['transactiondate'] = df['transactiondate'].dt.quarter\n",
    "    df = df.fillna(-1.0)\n",
    "    return df\n",
    "\n",
    "def MAE(y, ypred):\n",
    "    #logerror=log(Zestimate)−log(SalePrice)\n",
    "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\n",
    "\n",
    "train = pd.merge(train, properties, how='left', on='parcelid')\n",
    "y = train['logerror'].values\n",
    "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n",
    "properties = [] #memory\n",
    "\n",
    "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n",
    "col = [c for c in train.columns if c not in exc]\n",
    "\n",
    "train = get_features(train[col])\n",
    "test['transactiondate'] = '2016-01-01' #should use the most common training date\n",
    "test = get_features(test[col])\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1)\n",
    "reg.fit(train, y); print('fit...')\n",
    "print(MAE(y, reg.predict(train)))\n",
    "train = [];  y = [] #memory\n",
    "\n",
    "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
    "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "########################\n",
    "##  Combine and Save  ##\n",
    "########################\n",
    "########################\n",
    "\n",
    "##### COMBINE PREDICTIONS\n",
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = (1 - XGB_WEIGHT - BASELINE_WEIGHT) / (1 - OLS_WEIGHT)\n",
    "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\n",
    "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\n",
    "pred0 = xgb_weight0*xgb_pred + baseline_weight0*BASELINE_PRED + lgb_weight*p_test\n",
    "\n",
    "print( \"\\nCombined XGB/LGB/baseline predictions:\" )\n",
    "print( pd.DataFrame(pred0).head() )\n",
    "\n",
    "print( \"\\nPredicting with OLS and combining with XGB/LGB/baseline predicitons: ...\" )\n",
    "for i in range(len(test_dates)):\n",
    "    test['transactiondate'] = test_dates[i]\n",
    "    pred = OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0\n",
    "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n",
    "    print('predict...', i)\n",
    "\n",
    "print( \"\\nCombined XGB/LGB/baseline/OLS predictions:\" )\n",
    "print( submission.head() )\n",
    "\n",
    "\n",
    "\n",
    "##### WRITE THE RESULTS\n",
    "from datetime import datetime\n",
    "print( \"\\nWriting results to disk ...\" )\n",
    "submission.to_csv('sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n",
    "print( \"\\nFinished ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
