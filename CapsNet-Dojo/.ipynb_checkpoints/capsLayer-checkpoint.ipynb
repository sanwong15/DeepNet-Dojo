{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import cfg\n",
    "from utils import reduce_sum\n",
    "from utils import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsLayer(object):\n",
    "    '''\n",
    "    Capsule Layer\n",
    "    Argument Input:\n",
    "    (4D Tensor) \n",
    "    (1) num_outputs: integer (i.e: Number of capsule in this layer)\n",
    "    (2) vec_len: integer (i.e: Length of the output vector of this layer)\n",
    "    (3) layer_type: str (i.e: 'FC' or 'CONV')\n",
    "    (4) with_routing: boolean (i.e: Allowing this capsule to rout with lower-level capsule layer)\n",
    "    \n",
    "    Return:\n",
    "    (1) 4D Tensor\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_outputs, vec_len, layer_type='FC', with_routing=True):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.vec_len = vec_len\n",
    "        self.with_routing = with_routing\n",
    "        self.layer_type = layer_type\n",
    "        \n",
    "    def __call__(self, input, kernel_size=None, stride=None):\n",
    "        '''\n",
    "        kernel_size and stride will be useful when the layer is defined as CONV\n",
    "        '''\n",
    "        \n",
    "        if self.layer_type == 'CONV':\n",
    "            self.kernel_size = kernel_size\n",
    "            self.stride = stride\n",
    "            \n",
    "            #Handle case where routing is FALSE\n",
    "            if not self.with_routing:\n",
    "                # Without routing, CONV -> PrimaryCaps Layer\n",
    "                # Input: [batch_size,20,20,256]\n",
    "                \n",
    "                # Check input size (output from the 1st conv layer applied on input image)\n",
    "                assert input.get_shape() == [cfg.batch_size,20,20,256]\n",
    "                \n",
    "                '''conv2d(\n",
    "                            inputs,\n",
    "                            num_outputs,\n",
    "                            kernel_size,\n",
    "                            stride=1,\n",
    "                            padding='SAME',\n",
    "                            data_format=None,\n",
    "                            rate=1,\n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            normalizer_fn=None,\n",
    "                            normalizer_params=None,\n",
    "                            weights_initializer=initializers.xavier_initializer(),\n",
    "                            weights_regularizer=None,\n",
    "                            biases_initializer=tf.zeros_initializer(),\n",
    "                            biases_regularizer=None,\n",
    "                            reuse=None,\n",
    "                            variables_collections=None,\n",
    "                            outputs_collections=None,\n",
    "                            trainable=True,\n",
    "                            scope=None\n",
    "                        )\n",
    "                '''\n",
    "                #Conv1\n",
    "                '''[According to the paper]: Conv1 has 256, 9 Ã— 9 convolution kernels with a stride of 1 and ReLU activation.\n",
    "                This layer converts pixel intensities to the activities of local feature detectors that are then used as inputs to the primary capsules\n",
    "                \n",
    "                (i.e: self.kernal_size = 256*9*9)\n",
    "                \n",
    "                num_outputs: number of output capsule \n",
    "                ven_len: Length of the output vector\n",
    "                '''\n",
    "                capsules = tf.contrib.layers.conv2d(input, self.num_outputs*self.vec_len, self.kernel_size, self.stride, padding=\"VALID\", activation_fn=tf.nn.relu) # Leaving others to default setting\n",
    "\n",
    "                capsules = tf.reshape(capsules, (cfg.batch_size, -1, self.vec_len, 1))\n",
    "                # 32 output capsule * 6*6 output => 32*6*6 = 1152\n",
    "                # From last layer, it has depth of 256. As now we have 32 capsule, which means each\n",
    "                # capsule has depth of 256/32 = 8. Each capsule is 8-dim in depth.\n",
    "                # [batch_size, 1152, 8, 1] <- There are 1152 of 8-Dimension Tensor. Output to Primary Cap Layer\n",
    "                capsules = squash(capsules)\n",
    "                assert capsules.get_shape() == [cfg.batch_size, 1152, 8, 1] \n",
    "                return(capsules)\n",
    "            \n",
    "            \n",
    "            \n",
    "        if self.layer_type == 'FC': #FC layer refers to the digit Capsule layer where Routing on Agreement take place\n",
    "            if self.with_routing:\n",
    "                # DigitCaps (fully connected layer)\n",
    "                # Reshape input to [batch_size, 1152,1,8,1]\n",
    "                # Not sure about the following reshape:\n",
    "                self.input = tf.reshape(input, shape=(cfg.batch_size, -1, 1, input.shape[-2].value, 1))\n",
    "                \n",
    "                with tf.variable_scope('routing'):\n",
    "                    # b_IJ : [batch_size, num_caps_l, num_caps_lPLUS1, 1,1]\n",
    "                    # b_IJ is a 1 by 1 value which will later become c_IJ\n",
    "                    b_IJ = tf.constant(np.zeros([cfg.batch_size, input.shape[1].value, self.num_outputs,1,1],dtype=np.float32))\n",
    "                    capsules = routing(self.input, b_IJ)\n",
    "                    capsules = tf.squeeze(capsules, axis = 1)\n",
    "            return(capsules)\n",
    "        \n",
    "    def routing(input, b_IJ):\n",
    "        '''Arg: input_tensor: [batch_size, num_caps_l = 1152, 1, len(u_i)=8, 1]\n",
    "        \n",
    "           Return: [batch_size, num_caps_l_plus_one, len(v_j)=16, 1]\n",
    "           \n",
    "           u_i represents the vector output of capsule i in the layer l, and\n",
    "           v_j the vector output of capsule j in the layer l+1.\n",
    "        '''\n",
    "        \n",
    "        # W: [1, num_caps_i, num_caps_j*len_v_j, len_u_j, 1]\n",
    "        W = tf.get_variable('Weight',shape=(1,1152,160,8,1),dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=cfg.stddev))\n",
    "        biases = tf.get_variable('bias', shape=(1,1,10,16,1))\n",
    "        \n",
    "        # cal u_hat\n",
    "        '''\n",
    "        Since tf.matmul is a time-consuming op,\n",
    "        A better solution is using element-wise multiply, reduce_sum and reshape\n",
    "        ops instead. Matmul [a, b] x [b, c] is equal to a series ops as\n",
    "        element-wise multiply [a*c, b] * [a*c, b], reduce_sum at axis=1 and\n",
    "        reshape to [a, c]\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        tf.tile create a new tensor by replicating input multiples times\n",
    "        output tensor's i_th dimension has input.dims(i)*multiples[i]\n",
    "        elements and the value of input are replicated multiples[i] times along\n",
    "        the i_th dimension\n",
    "        \n",
    "        Example: [a b c d] by [2] output [a b c d a b c d]\n",
    "        '''\n",
    "        \n",
    "        # input_tensor: [batch_size, num_caps_l = 1152, 1, len(u_i)=8, 1]\n",
    "        input = tf.tile(input, [1,1,160,1,1])\n",
    "        # Validate if input shape \n",
    "        assert input.get_shape() == [cfg.batch_size,1152,160,8,1]\n",
    "        \n",
    "        u_hat = tf.reduce_sum(W*input, axis=3, keepdims = True) # Element-wise sum\n",
    "        u_hat = tf.reshape(u_hat, shape=[-1,1152,10,16,1])\n",
    "        #check size\n",
    "        assert u_hat.get_shape() == [cfg.batch_size,1152,10,16,1]\n",
    "        \n",
    "        # During forward pass, u_hat_stopped == u_hat\n",
    "        # No update during backprop. no gradient pass either\n",
    "        u_hat_stopped = tf.stop_gradient(u_hat,name='stop_gradient')\n",
    "        \n",
    "        for r_iter in range(cfg.iter_routing):\n",
    "            with tf.variable('iter_'+str(r_iter)):\n",
    "                #[batch_size, 1152, 10, 1, 1]\n",
    "                c_IJ = softmax(b_IJ, axis=2)\n",
    "                \n",
    "                if r_iter == cfg.iter_routing -1: #last iteration: we use u_hat\n",
    "                    s_J = tf.multiply(c_IJ,u_hat)\n",
    "                    s_J = reduce_sum(s_J,axis=1,keepdims=True) + biases\n",
    "                    assert s_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "                    \n",
    "                    v_J = squash(s_J)\n",
    "                    assert v_J.get_shape() == [cfg.batch_size, 1,10,16,1]\n",
    "                elif r_iter < cfg.iter_routing-1:\n",
    "                    s_J = tf.multiply(c_IJ,u_hat_stopped)\n",
    "                    s_J = reduce_sum(s_J,axis=1,keepdims=True)+biases\n",
    "                    v_J = squash(s_J)\n",
    "                    \n",
    "                    \n",
    "                    # Reshape and tile v_J from [batch_size, 1, 10, 16, 1]\n",
    "                    # to match with u_hat_stopped: [batch_size, 1152, 10,16, 1]\n",
    "                    # b_IJ += u_hat_stopped^T * v_J\n",
    "                    v_J_tiled = tf.tile(v_J, [1,1152,1,1,1])\n",
    "                    \n",
    "                    # v_J_tiled: [batch_size, 1152, 10,16, 1]\n",
    "                    # u_hat_stopped: [batch_size,1152,10,16,1]\n",
    "                    u_produce_v = reduce_sum(u_hat_stopped*v_J_tiled, axis=3, keepdims=True)\n",
    "                    assert u_produce_v.get_shape() == [cfg.batch_size,1152,10,1,1]\n",
    "                    \n",
    "                    # b_IJ +=\n",
    "                    b_IJ += u_produce_v\n",
    "                    \n",
    "                    \n",
    "        return(v_J)\n",
    "    \n",
    "    def squash(vector):\n",
    "        '''\n",
    "        Input: tensor with shape: [batch_size, 1, num_caps, vec_len, 1]\n",
    "        \n",
    "        Return: same shape. squashed in vec_len dimension\n",
    "        '''\n",
    "        \n",
    "        vec_squashed_norm = reduce_sum(tf.square(vector),-2,keepdims=True)\n",
    "        scalar_factor = vec_squashed_norm/(1+vec_squashed_norm)/tf.sqrt(vec_squashed_norm + epsilon)\n",
    "        vec_squashed = scalar_factor*vector\n",
    "        \n",
    "        return(vec_squashed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
